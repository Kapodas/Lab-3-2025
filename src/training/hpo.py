import optuna
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import lightgbm as lgb
import os
from clearml import Task, Dataset, Logger

def main():
    print("=" * 60)
    print("HPO –î–õ–Ø –†–ï–ì–†–ï–°–°–ò–ò (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –æ–¥–Ω—É –∑–∞–¥–∞—á—É –¥–ª—è –≤—Å–µ–≥–æ HPO
    task = Task.init(
        project_name='Lab3_Weather_Forecasting',
        task_name='HPO_Regression_temp_avg',
        task_type='optimizer'
    )
    
    logger = Logger.current_logger()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    dataset = Dataset.get(
        dataset_project='Lab3_Weather_Forecasting',
        dataset_name='London_Weather_Temperature_v1',
        only_completed=True,
        alias='weather_data_regression'
    )
    
    dataset_path = dataset.get_local_copy()
    csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]
    csv_path = os.path.join(dataset_path, csv_files[0])
    
    df = pd.read_csv(csv_path)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º temp_avg)
    exclude_features = [
        'date', 'rain_probability',  # rain_probability –∏—Å–∫–ª—é—á–∞–µ–º, —Ç.–∫. —ç—Ç–æ –±–∏–Ω–∞—Ä–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    ]
    
    features = [col for col in df.columns if col not in exclude_features]
    print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º {len(features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    X = df[features]
    y = df['temp_avg']  # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - —Å—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    n = len(df)
    train_size = int(n * 0.6)
    val_size = int(n * 0.2)
    
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    X_val = X.iloc[train_size:train_size+val_size]
    y_val = y.iloc[train_size:train_size+val_size]
    X_test = X.iloc[train_size+val_size:]
    y_test = y.iloc[train_size+val_size:]
    
    def objective(trial):
        """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Optuna - –†–ï–ì–†–ï–°–°–ò–Ø"""
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'num_leaves': trial.suggest_int('num_leaves', 10, 50),
            'max_depth': trial.suggest_int('max_depth', 3, 8),
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),
            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),
            'n_estimators': 150,
            'verbose': -1,
            'random_state': 42
        }
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º LGBMRegressor –≤–º–µ—Å—Ç–æ LGBMClassifier
        model = lgb.LGBMRegressor(**params)
        
        model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            eval_metric='rmse',
            callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
        )
        
        # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º RMSE –∏–ª–∏ MAE –∫–∞–∫ –º–µ—Ç—Ä–∏–∫—É
        y_pred = model.predict(X_val)
        rmse = np.sqrt(mean_squared_error(y_val, y_pred))
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–¥–∞—á—É
        logger.report_scalar('HPO_Trials', 'rmse', rmse, trial.number)
        
        # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º RMSE (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
        return rmse
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é (—Ç–µ–ø–µ—Ä—å direction='minimize' –¥–ª—è RMSE)
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ 15 –∏—Å–ø—ã—Ç–∞–Ω–∏–π HPO –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
    study = optuna.create_study(direction='minimize')  # –ò–ó–ú–ï–ù–ï–ù–û: minimize —Ç.–∫. RMSE
    study.optimize(objective, n_trials=15, show_progress_bar=True)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\n‚úÖ –õ—É—á—à–∏–π RMSE: {study.best_value:.4f}¬∞C")
    print("üéØ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    
    # –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    print("\nüèãÔ∏è  –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    X_train_full = pd.concat([X_train, X_val])
    y_train_full = pd.concat([y_train, y_val])
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º LGBMRegressor
    best_model = lgb.LGBMRegressor(
        objective='regression',
        metric='rmse',
        verbose=-1,
        random_state=42,
        n_estimators=200,
        **study.best_params
    )
    
    best_model.fit(X_train_full, y_train_full)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    y_pred_test = best_model.predict(X_test)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    test_mae = mean_absolute_error(y_test, y_pred_test)
    test_r2 = r2_score(y_test, y_pred_test)
    
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–µ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è):")
    print(f"  RMSE: {test_rmse:.4f}¬∞C")
    print(f"  MAE: {test_mae:.4f}¬∞C")
    print(f"  R¬≤: {test_r2:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    os.makedirs('models', exist_ok=True)
    model_path = 'models/best_hpo_regression.txt'  # –ò–ó–ú–ï–ù–ï–ù–û –∏–º—è —Ñ–∞–π–ª–∞
    best_model.booster_.save_model(model_path)
    
    print(f"\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    logger.report_scalar('Final_Model', 'test_rmse', test_rmse, 0)
    logger.report_scalar('Final_Model', 'test_mae', test_mae, 0)
    logger.report_scalar('Final_Model', 'test_r2', test_r2, 0)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API
    feature_info = {
        'features': features,
        'target': 'temp_avg',
        'best_params': study.best_params,
        'test_metrics': {
            'rmse': float(test_rmse),
            'mae': float(test_mae),
            'r2': float(test_r2)
        }
    }
    
    import json
    with open('models/feature_info.json', 'w') as f:
        json.dump(feature_info, f, indent=2)
    
    print(f"\nüíæ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/feature_info.json")
    
    print(f"\nüîó Task URL: http://localhost:8080/projects/{task.project}/experiments/{task.id}")
    
    return study.best_params, test_rmse

if __name__ == "__main__":
    best_params, test_score = main()
    print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/best_hpo_regression.txt")