import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
from clearml import Task, Dataset, OutputModel, Logger
import os
import warnings
from datetime import datetime
import json

# –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

def setup_task():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–¥–∞—á–∏ ClearML"""
    print("=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –ü–†–û–ì–ù–û–ó–ê –°–†–ï–î–ù–ï–ô –¢–ï–ú–ü–ï–†–ê–¢–£–†–´")
    print("=" * 60)
    
    task = Task.init(
        project_name='Lab3_Weather_Forecasting',
        task_name=f'Temperature_Prediction_Model_{datetime.now().strftime("%Y%m%d_%H%M")}',
        task_type=Task.TaskTypes.training,
        reuse_last_task_id=False,
        tags=['lightgbm', 'regression', 'weather', 'temperature', 'lab3']
    )
    
    return task

def load_dataset(task):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ ClearML –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ ClearML...")
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ ClearML
        dataset = Dataset.get(
            dataset_project='Lab3_Weather_Forecasting',
            dataset_name='London_Weather_Temperature_v1',
            only_completed=True,
            alias='weather_data'
        )
        
        dataset_path = dataset.get_local_copy()
        print(f"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –≤: {dataset_path}")
        
        # –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–∞
        csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]
        if not csv_files:
            raise FileNotFoundError("CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ")
        
        csv_path = os.path.join(dataset_path, csv_files[0])
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {csv_path}")
        
        df = pd.read_csv(csv_path)
        dataset_id = dataset.id
        
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ ClearML: {e}")
        print("–ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª...")
        
        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        csv_path = "../data/weather_data.csv"
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            dataset_id = 'local_file'
        else:
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            print("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            df = create_sample_data()
            dataset_id = 'sample_data'
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'])
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
    if 'date' in df.columns:
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {df['date'].min().date()} - {df['date'].max().date()}")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
    task.get_logger().report_text(f"Dataset loaded: {dataset_id}, shape: {df.shape}")
    
    return df, dataset_id

def create_sample_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    dates = pd.date_range(start='2022-01-01', end='2024-12-31', freq='D')
    n_samples = len(dates)
    
    np.random.seed(42)
    df = pd.DataFrame({
        'date': dates,
        'temp_max': np.random.normal(15, 5, n_samples),
        'temp_min': np.random.normal(8, 3, n_samples),
        'precipitation_sum': np.random.exponential(0.5, n_samples),
        'precipitation_hours': np.random.poisson(2, n_samples),
        'weather_code': np.random.randint(0, 10, n_samples),
        'wind_speed_max': np.random.normal(10, 3, n_samples),
        'rain_sum': np.random.exponential(0.3, n_samples)
    })
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - —Å—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
    df['temp_avg'] = (df['temp_max'] + df['temp_min']) / 2
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–∞–≥–∏ –∏ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ –¥–ª—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    for lag in [1, 2, 3, 7, 14]:
        df[f'temp_avg_lag_{lag}'] = df['temp_avg'].shift(lag)
        df[f'temp_max_lag_{lag}'] = df['temp_max'].shift(lag)
        df[f'temp_min_lag_{lag}'] = df['temp_min'].shift(lag)
        df[f'precip_lag_{lag}'] = df['precipitation_sum'].shift(lag)
    
    for window in [3, 7, 14]:
        df[f'temp_avg_avg_{window}d'] = df['temp_avg'].rolling(window).mean()
        df[f'temp_max_avg_{window}d'] = df['temp_max'].rolling(window).mean()
        df[f'temp_min_avg_{window}d'] = df['temp_min'].rolling(window).mean()
        df[f'precip_avg_{window}d'] = df['precipitation_sum'].rolling(window).mean()
    
    # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['day_of_week'] = df['date'].dt.dayofweek
    df['day_of_year'] = df['date'].dt.dayofyear
    df['month'] = df['date'].dt.month
    df['year'] = df['date'].dt.year
    
    # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)
    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)
    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
    
    # –£–¥–∞–ª—è–µ–º NaN
    df = df.dropna().reset_index(drop=True)
    
    return df

def prepare_features(df, task):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"""
    print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã...")
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    exclude_cols = [
        'date', 'temp_avg',  # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    ]
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö)
    features = [col for col in df.columns if col not in exclude_cols]
    
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    X = df[features]
    y = df['temp_avg']
    
    return X, y, features

def split_data_temporal(X, y, test_size=0.15, val_size=0.15):
    """–í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    print("\nüìä –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    
    n_samples = len(X)
    train_size = int(n_samples * (1 - test_size - val_size))
    val_size_abs = int(n_samples * val_size)
    
    X_train = X.iloc[:train_size]
    y_train = y.iloc[:train_size]
    
    X_val = X.iloc[train_size:train_size + val_size_abs]
    y_val = y.iloc[train_size:train_size + val_size_abs]
    
    X_test = X.iloc[train_size + val_size_abs:]
    y_test = y.iloc[train_size + val_size_abs:]
    
    print(f"Train: {len(X_train)} –∑–∞–ø–∏—Å–µ–π ({len(X_train)/n_samples*100:.1f}%)")
    print(f"Val:   {len(X_val)} –∑–∞–ø–∏—Å–µ–π ({len(X_val)/n_samples*100:.1f}%)")
    print(f"Test:  {len(X_test)} –∑–∞–ø–∏—Å–µ–π ({len(X_test)/n_samples*100:.1f}%)")
    
    return X_train, y_train, X_val, y_val, X_test, y_test

def train_model(X_train, y_train, X_val, y_val, task):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LightGBM –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
    print("\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –†–ï–ì–†–ï–°–°–ò–ò
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'learning_rate': 0.05,
        'num_leaves': 31,
        'max_depth': 6,
        'min_child_samples': 20,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'n_estimators': 200,
        'verbose': -1,
        'random_state': 42,
    }
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫ –∑–∞–¥–∞—á–µ ClearML
    params = task.connect(params)
    
    print("üèãÔ∏è  –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LightGBM...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è LightGBM
    train_data = lgb.Dataset(X_train, label=y_train)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
    
    # –û–±—É—á–µ–Ω–∏–µ —Å –æ–±—Ä–∞—Ç–Ω—ã–º –≤—ã–∑–æ–≤–æ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ ClearML
    model = lgb.train(
        params,
        train_data,
        valid_sets=[val_data],
        num_boost_round=200,
        callbacks=[
            lgb.early_stopping(stopping_rounds=30),
            lgb.log_evaluation(period=20),
            log_to_clearml(task)
        ]
    )
    
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return model

def log_to_clearml(task):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤ ClearML"""
    def _callback(env):
        if env.iteration % 10 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π
            for data_name, eval_name, result, _ in env.evaluation_result_list:
                metric_name = f"{data_name}_{eval_name}"
                task.get_logger().report_scalar(
                    title="Training Metrics",
                    series=metric_name,
                    value=result,
                    iteration=env.iteration
                )
    return _callback

def evaluate_model(model, X_test, y_test, task):
    """–û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print("\nüìà –û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = model.predict(X_test)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    metrics = {
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
        'mae': mean_absolute_error(y_test, y_pred),
        'r2': r2_score(y_test, y_pred),
        'mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100,
        'std_error': np.std(y_test - y_pred)
    }
    
    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(f"  RMSE: {metrics['rmse']:.2f}¬∞C")
    print(f"  MAE: {metrics['mae']:.2f}¬∞C")
    print(f"  R¬≤: {metrics['r2']:.3f}")
    print(f"  MAPE: {metrics['mape']:.1f}%")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ ClearML
    logger = Logger.current_logger()
    for name, value in metrics.items():
        logger.report_scalar(
            title='Test Metrics',
            series=name,
            value=value,
            iteration=0
        )
    
    # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ—Ä—Ç–µ–∂ –∏–∑ 4 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    return y_pred, None, metrics, None  # y_pred_proba –∏ cm –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

def analyze_feature_importance(model, features, X_test, task):
    """–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    importances = model.feature_importance(importance_type='gain')
    importance_df = pd.DataFrame({
        'feature': features,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    print("\nüèÜ –¢–æ–ø-10 –≤–∞–∂–Ω–µ–π—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, row in importance_df.head(10).iterrows():
        print(f"  {row['feature']}: {row['importance']:.2f}")
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    task.get_logger().report_table(
        title='Feature Importance',
        series='All Features',
        table_plot=importance_df
    )
    
    return importance_df

def create_plots(model, importance_df, X_test, y_test, y_pred, task):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
    print("\nüé® –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
    
    # 1. –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    plt.figure(figsize=(12, 8))
    top_features = importance_df.head(15)
    plt.barh(range(len(top_features)), top_features['importance'])
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Importance (Gain)')
    plt.title('Top 15 Feature Importances - Temperature Prediction')
    plt.tight_layout()
    task.get_logger().report_matplotlib_figure(
        title='Feature Importance Plot',
        series='Top 15 Features',
        figure=plt,
        iteration=0
    )
    plt.close()
    
    # 2. –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π vs —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.5, edgecolors='k')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Temperature (¬∞C)')
    plt.ylabel('Predicted Temperature (¬∞C)')
    plt.title('Actual vs Predicted Temperature')
    plt.grid(True, alpha=0.3)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
    max_val = max(y_test.max(), y_pred.max())
    min_val = min(y_test.min(), y_pred.min())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')
    
    plt.legend()
    plt.tight_layout()
    task.get_logger().report_matplotlib_figure(
        title='Model Performance',
        series='Actual vs Predicted',
        figure=plt,
        iteration=0
    )
    plt.close()
    
    # 3. –ì—Ä–∞—Ñ–∏–∫ –æ—à–∏–±–æ–∫
    errors = y_test - y_pred
    plt.figure(figsize=(10, 6))
    plt.hist(errors, bins=30, edgecolor='black', alpha=0.7)
    plt.xlabel('Prediction Error (¬∞C)')
    plt.ylabel('Frequency')
    plt.title('Distribution of Prediction Errors')
    plt.axvline(x=0, color='r', linestyle='--', label='Zero Error')
    plt.legend()
    plt.tight_layout()
    task.get_logger().report_matplotlib_figure(
        title='Model Errors',
        series='Error Distribution',
        figure=plt,
        iteration=0
    )
    plt.close()

def save_model(model, features, metrics, task):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs('models', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path_txt = 'models/temperature_model.txt'
    model_path_json = 'models/temperature_model.json'
    
    model.save_model(model_path_txt)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫: {model_path_txt}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    metadata = {
        'features': features,
        'metrics': metrics,
        'created_at': datetime.now().isoformat(),
        'model_type': 'LightGBM_Regressor',
        'version': '1.0.0',
        'target_variable': 'temp_avg',
        'units': 'degrees_celsius'
    }
    
    with open(model_path_json, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫: {model_path_json}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ ClearML
    print("\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ ClearML...")
    task.upload_artifact('trained_model', model_path_txt)
    task.upload_artifact('model_metadata', model_path_json)
    
    return model_path_txt, model_path_json

def register_model_in_clearml(model_path, task, features, metrics, dataset_id):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ ClearML Model Registry"""
    print("\nüè∑Ô∏è  –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ Model Registry...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç OutputModel –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        output_model = OutputModel(
            task=task,
            framework="LightGBM",
            name="Temperature_Predictor",
            tags=['production', 'weather', 'regression', 'temperature', 'lab3']  # –ò–ó–ú–ï–ù–ï–ù–û
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
        output_model.update_weights(
            weights_filename=model_path,
            auto_delete_file=False,
            iteration=0
        )
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        output_model.update_design(
            config_text=json.dumps({
                'features': features,
                'metrics': metrics,
                'dataset_id': dataset_id,
                'task_id': task.id,
                'created': datetime.now().isoformat(),
                'model_type': 'Temperature Regression',
                'target': 'temp_avg'
            }, indent=2)
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–≥–∏
        output_model.set_tags(['v1.0', 'lightgbm', 'london', 'temperature_prediction'])
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞!")
        print(f"   Model ID: {output_model.id}")
        print(f"   Model Name: {output_model.name}")
        print(f"   URL: http://localhost:8080/models/{output_model.id}")
        
        return output_model
        
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        print("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏...")
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –∑–∞–¥–∞—á–∏
        task.upload_artifact('production_model', model_path, metadata={
            'features': features,
            'metrics': metrics,
            'registered_manually': True
        })
        
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –∑–∞–¥–∞—á–∏")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–¥–∞—á–∏ ClearML
        task = setup_task()
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df, dataset_id = load_dataset(task)
        
        # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X, y, features = prepare_features(df, task)
        
        # 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, y_train, X_val, y_val, X_test, y_test = split_data_temporal(
            X, y, test_size=0.15, val_size=0.15
        )
        
        # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = train_model(X_train, y_train, X_val, y_val, task)
        
        # 6. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        y_pred, y_pred_proba, metrics, cm = evaluate_model(model, X_test, y_test, task)
        
        # 7. –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        importance_df = analyze_feature_importance(model, features, X_test, task)
        
        # 8. –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        create_plots(model, importance_df, X_test, y_test, y_pred, task)  # –ü–µ—Ä–µ–¥–∞–µ–º y_pred –≤–º–µ—Å—Ç–æ y_pred_proba
        
        # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_path_txt, model_path_json = save_model(model, features, metrics, task)
        
        # 10. –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ ClearML
        registered_model = register_model_in_clearml(
            model_path_txt, task, features, metrics, dataset_id
        )
        
        # 11. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "=" * 60)
        print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("=" * 60)
        
        print(f"\nüìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
        for name, value in metrics.items():
            print(f"  {name}: {value:.4f}")
        
        print(f"\nüîó –°—Å—ã–ª–∫–∏ –≤ ClearML:")
        print(f"  –ó–∞–¥–∞—á–∞: http://localhost:8080/projects/{task.project}/experiments/{task.id}")
        if registered_model:
            print(f"  –ú–æ–¥–µ–ª—å: http://localhost:8080/models/{registered_model.id}")
        
        print(f"\nüìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        print(f"  –ú–æ–¥–µ–ª—å: {model_path_txt}")
        print(f"  –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {model_path_json}")
        
        print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("  1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ ClearML")
        print("  2. –û–±–Ω–æ–≤–∏—Ç–µ API —Å–µ—Ä–≤–∏—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        print("  3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        return {
            'task': task,
            'model': model,
            'metrics': metrics,
            'model_path': model_path_txt,
            'registered_model': registered_model
        }
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    result = main()
    
    if result:
        print(f"\nüéâ –í—Å–µ —ç—Ç–∞–ø—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print(f"Task ID: {result['task'].id}")
    else:
        print("\n‚ö†Ô∏è  –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")